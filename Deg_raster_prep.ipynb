{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBFdgtmqOh93bGZfMxdmOv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coltongerth/Degradation-data-pre-post-process-notebook/blob/main/Deg_raster_prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Library Imports"
      ],
      "metadata": {
        "id": "wwTfd8eh891n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ljoel5rryF9O"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# !pip install fiona\n",
        "!pip install pandas\n",
        "# !pip install tensorflow\n",
        "!pip install shapely\n",
        "!pip install jupyter-server-proxy\n",
        "!pip install affine==2.3.1\n",
        "!pip install attrs==22.2.0\n",
        "!pip install bounded-pool-executor==0.0.3\n",
        "!pip install certifi==2022.12.7\n",
        "!pip install click==8.1.3\n",
        "!pip install click-plugins==1.1.1\n",
        "!pip install cligj==0.7.2\n",
        "!pip install numpy==1.24.1\n",
        "!pip install python-dateutil==2.8.2\n",
        "!pip install pytz==2022.7\n",
        "!pip install rasterio==1.3.4\n",
        "!pip install scipy==1.10.0\n",
        "!pip install six==1.16.0\n",
        "!pip install snuggs==1.4.7\n",
        "!pip install statsmodels==0.13.5\n",
        "!pip install geopandas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inputs"
      ],
      "metadata": {
        "id": "Afa9toyr83hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IF YOU HAVE MEMORY CRASHING ISSUES LOWER THIS NUMBER (KEEP IN POWERS OF 2: 2, 4, 8, 16, 32 ...)\n",
        "BLOCKSIZE = 256\n",
        "\n",
        "# INPUTS HERE\n",
        "zone_name = \"BpsMskR2Fin\"\n",
        "boundary_name = \"BpsMskR2Fin\"\n",
        "\n",
        "# DONT WORRY ABOUT THESE\n",
        "gcs_degradation_path = \"gs://fuelcast-data/degradation/\"\n",
        "gcs_rpms_path = \"gs://fuelcast-data/rpms/\"\n",
        "zone_raster_path = f\"gdrive/MyDrive/{zone_name}.tif\"\n",
        "post_cut_zone_raster_path = f\"./data/{zone_name}/{zone_name}_{boundary_name}_cut.tif\"\n",
        "boundary_raster_path = f\"gdrive/MyDrive/{boundary_name}.tif\"\n",
        "data_raster_path = f\"./data/{zone_name}/{boundary_name}_rpms_stack.tif\"\n",
        "dummy_path = \"./test.tif\""
      ],
      "metadata": {
        "id": "rOX01COeyh0b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main converter from raster down to CSV"
      ],
      "metadata": {
        "id": "K84xA69J85Px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import fiona\n",
        "# import cupy as cp\n",
        "# import pickle\n",
        "\n",
        "import os\n",
        "import rasterio\n",
        "import asyncio\n",
        "import warnings\n",
        "# import geopandas as gpd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio.mask\n",
        "from shapely.geometry import box\n",
        "# from shapely.geometry import shape\n",
        "from scipy import stats as st\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "from rasterio.mask import mask\n",
        "from dask.delayed import delayed\n",
        "# from dotenv import load_doten\n",
        "from IPython.display import display\n",
        "from rasterio.windows import Window\n",
        "from rasterio.profiles import DefaultGTiffProfile\n",
        "from concurrent.futures import ProcessPoolExecutor, wait, FIRST_COMPLETED, ALL_COMPLETED\n",
        "\n",
        "data_type = \"float32\"\n",
        "drive.mount('/content/gdrive')\n",
        "def raster_to_csv(raster, file_path):\n",
        "    \"\"\"Convert a raster dataset to CSV, ensuring valid values are extracted.\"\"\"\n",
        "    with rasterio.open(raster) as src:\n",
        "        # Read metadata and print for debugging\n",
        "        print(\"Metadata:\", src.meta)\n",
        "\n",
        "        # Read the first band\n",
        "        band1 = src.read(1)\n",
        "\n",
        "        # Print minimum and maximum values for debugging\n",
        "        print(\"Min value:\", band1.min())\n",
        "        print(\"Max value:\", band1.max())\n",
        "\n",
        "        # Check the NoData value\n",
        "        nodata = src.nodata\n",
        "        print(\"NoData value:\", nodata)\n",
        "\n",
        "        # Read rows and cols indices\n",
        "        rows, cols = np.indices(band1.shape)\n",
        "\n",
        "        # Transform the indices to coordinates\n",
        "        x_coords, y_coords = src.transform * (cols, rows)\n",
        "\n",
        "        # Flatten arrays\n",
        "        x_coords = x_coords.flatten()\n",
        "        y_coords = y_coords.flatten()\n",
        "        values = band1.flatten()\n",
        "\n",
        "        # Filter out NoData values if NoData is not None\n",
        "        if nodata is not None:\n",
        "            mask = values != nodata\n",
        "            x_coords = x_coords[mask]\n",
        "            y_coords = y_coords[mask]\n",
        "            values = values[mask]\n",
        "\n",
        "        # Print a sample of values for debugging\n",
        "        print(\"Sample values:\", values[:10])\n",
        "\n",
        "        # Create a DataFrame and save to CSV\n",
        "        df = pd.DataFrame({\n",
        "            'X': x_coords,\n",
        "            'Y': y_coords,\n",
        "            'Zone': values\n",
        "        })\n",
        "\n",
        "        # Save to CSV\n",
        "        df.to_csv(file_path, index=False)\n",
        "        print(f\"CSV saved to {file_path}\")\n",
        "\n",
        "def write_multiband_raster_to_single_csv(raster, file_name):\n",
        "    \"\"\"Utility function to write multiband raster data to a single CSV file.\"\"\"\n",
        "    with rasterio.open(raster) as src:\n",
        "        all_bands_data = {}\n",
        "\n",
        "        # Get the coordinates once since they are the same for all bands\n",
        "        rows, cols = np.indices((src.height, src.width))\n",
        "        x_coords, y_coords = src.transform * (cols, rows)\n",
        "        x_coords = x_coords.flatten()\n",
        "        y_coords = y_coords.flatten()\n",
        "\n",
        "        # Store the coordinates in the DataFrame dictionary\n",
        "        all_bands_data['X'] = x_coords\n",
        "        all_bands_data['Y'] = y_coords\n",
        "\n",
        "        # Iterate over each band\n",
        "        for band_index in range(1, src.count + 1):  # src.count gives the number of bands\n",
        "            band = src.read(band_index)  # Read each band\n",
        "            values = band.flatten()\n",
        "\n",
        "            # Add the band's values to the dictionary with a key for each band\n",
        "            all_bands_data[f'value_band_{band_index}'] = values\n",
        "\n",
        "        # Convert the dictionary to a DataFrame\n",
        "        df = pd.DataFrame(all_bands_data)\n",
        "\n",
        "        # drop rows where all bands are 0\n",
        "        df = df[(df != 0).any(axis=1)]\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        df.to_csv(file_name, index=False)\n",
        "\n",
        "# async def raster_stacker(in_ds, out_ds, bounds):\n",
        "def raster_stacker(id, in_ds, out_ds, bounds):\n",
        "\n",
        "    with rasterio.open(in_ds) as src_ds:\n",
        "        win = src_ds.window(\n",
        "            bottom=bounds.bottom,\n",
        "            right=bounds.right,\n",
        "            top=bounds.top,\n",
        "            left=bounds.left,\n",
        "        )\n",
        "        print(f\"in: {in_ds} || {win}\")\n",
        "        input_data = src_ds.read(1, window=win)\n",
        "        out_ds.write_band(id, input_data)\n",
        "\n",
        "\n",
        "\n",
        "# with rasterio.Env(GDAL_NUM_THREADS=\"ALL_CPUS\", verbose=2, GOOGLE_APPLICATION_CREDENTIALS=os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\", path_to_credentials)):\n",
        "with rasterio.Env(GDAL_NUM_THREADS=\"ALL_CPUS\", verbose=2):\n",
        "\n",
        "      boundary_ds = rasterio.open(boundary_raster_path)\n",
        "      bounds = boundary_ds.bounds\n",
        "      # bounds = [-114.174042,42.633959,-112.858429,43.608239]\n",
        "\n",
        "      profile = boundary_ds.profile\n",
        "      profile.update(\n",
        "          blockxsize=BLOCKSIZE,\n",
        "          blockysize=BLOCKSIZE,\n",
        "          tiled=True,\n",
        "          compress=\"DEFLATE\",\n",
        "          # predictor=2,\n",
        "          BIGTIFF=\"Yes\",\n",
        "          dtype=data_type\n",
        "\n",
        "      )\n",
        "\n",
        "      od = f\"./data/{zone_name}\"\n",
        "      if not os.path.exists(od):\n",
        "          os.makedirs(od)\n",
        "\n",
        "      if os.path.exists(post_cut_zone_raster_path):\n",
        "          print(f\"cut zone data {post_cut_zone_raster_path} exists.\")\n",
        "      else:\n",
        "          # Open the larger raster and cut it using the bounds of the smaller raster\n",
        "          with rasterio.open(zone_raster_path) as dx:\n",
        "              # Calculate the window from the smaller raster's bounds\n",
        "              win = dx.window(left=bounds.left, bottom=bounds.bottom,\n",
        "                              right=bounds.right, top=bounds.top)\n",
        "\n",
        "              # Read the data from the larger raster within the window\n",
        "              dat = dx.read(window=win)\n",
        "              # Adjust the profile for the output file\n",
        "              profile = dx.profile\n",
        "              profile.update({\n",
        "                  'height': dat.shape[1],\n",
        "                  'width': dat.shape[2],\n",
        "                  'transform': rasterio.windows.transform(win, dx.transform)\n",
        "              })\n",
        "\n",
        "              # Write the cut raster to a new file\n",
        "              with rasterio.open(post_cut_zone_raster_path, 'w', **profile) as dst:\n",
        "                  dst.write(dat)\n",
        "\n",
        "\n",
        "      raster_to_csv(post_cut_zone_raster_path, f'gdrive/MyDrive/output/{zone_name}_{boundary_name}_cut.csv')\n",
        "\n",
        "\n",
        "      files = [f\"https://storage.googleapis.com/fuelcast-public/rpms/{y}/rpms_{y}.tif\" for y in range(1984, 2024) if y != 2012]\n",
        "\n",
        "      profile.update(count=len(files))\n",
        "\n",
        "      print(\"Stacking raster\")\n",
        "\n",
        "      stack_path = data_raster_path\n",
        "\n",
        "      if os.path.exists(stack_path):\n",
        "          print(f\"Stacked raster {stack_path} already exists.\")\n",
        "      else:\n",
        "          with rasterio.open(stack_path, \"w\", **profile) as dst:\n",
        "              print(f\"out: {dst} || {dst.bounds}\")\n",
        "\n",
        "              for id, layer in enumerate(files, start=1):\n",
        "                  print(f\"in: {layer}\")\n",
        "                  raster_stacker(id, layer, dst, bounds)\n",
        "              # raster_stacker(1, files[0], dst, bounds)\n",
        "\n",
        "\n",
        "      write_multiband_raster_to_single_csv(stack_path, f'gdrive/MyDrive/output/{boundary_name}_rpms_stack_cut.csv')\n"
      ],
      "metadata": {
        "id": "-afunZbfyIsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean up CSV files for Rstudio Degradation Script: mean filling zeroes."
      ],
      "metadata": {
        "id": "hFfM4A4r5Mg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zones_df = pd.read_csv(f'gdrive/MyDrive/output/{zone_name}_{boundary_name}_cut.csv')\n",
        "zones_df = zones_df[zones_df['value'] != -32768]\n",
        "zones_df.rename(columns={'x': 'X', 'y': 'Y'}, inplace=True)\n",
        "zones_df.to_csv(f'gdrive/MyDrive/output/{zone_name}_{boundary_name}_cut.csv', index=False)\n",
        "\n",
        "new_cut_rpms_filtered = pd.read_csv(f'gdrive/MyDrive/output/{boundary_name}_rpms_stack_cut.csv')\n",
        "def replace_zeros_with_row_mean(df):\n",
        "    # Extract only the 'band' columns for processing\n",
        "    band_columns = [col for col in df.columns if col.startswith('band')]\n",
        "\n",
        "    # Iterate over each row\n",
        "    for index, row in df.iterrows():\n",
        "        # Calculate the mean of non-zero values in the row\n",
        "        mean_value = row[band_columns][row[band_columns] != 0].mean()\n",
        "\n",
        "        # Replace zeroes with the calculated mean\n",
        "        df.loc[index, band_columns] = row[band_columns].replace(0, mean_value)\n",
        "\n",
        "    return df\n",
        "\n",
        "new_cut_rpms_filtered_mean_filled = replace_zeros_with_row_mean(new_cut_rpms_filtered)\n",
        "\n",
        "new_cut_rpms_filtered_mean_filled.to_csv(f'gdrive/MyDrive/output/{boundary_name}_rpms_stack_cut_filtered_mean_filled.csv', index=False)"
      ],
      "metadata": {
        "id": "FpuZWroX1a0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert results after running Degradation in Rstudio back to Raster"
      ],
      "metadata": {
        "id": "sI3bdNlE5HIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rasterio.transform import from_origin\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "data = pd.read_csv('gdrive/MyDrive/output/comparison_analysis_zones_rpms_full_with_good_zone_res.csv')\n",
        "\n",
        "# CHANGE THIS IF YOUR CSV HAS X,Y or LATITUDE,LONGITUDE\n",
        "lat_long = False\n",
        "\n",
        "if lat_long == False:\n",
        "    x_col = \"X\"\n",
        "    y_col = \"Y\"\n",
        "else:\n",
        "    x_col = \"longitude\"\n",
        "    y_col = \"latitude\"\n",
        "\n",
        "\n",
        "\n",
        "# want t test, slope test, t pvalue, slope pvalue\n",
        "bands = {\n",
        "    \"t(mean)\":\"t_mean\",\n",
        "    \"t(slope)\":\"t_slope\",\n",
        "    \"p(|t|<T)(mean)\":\"p_mean\",\n",
        "    \"p(|t|<T)(slope)\":\"p_slope\"\n",
        "}\n",
        "\n",
        "pixel_size = 0.0002694945852358564\n",
        "\n",
        "# Define the extent of the data\n",
        "x_min, x_max = data[x_col].min(), data[x_col].max()\n",
        "y_min, y_max = data[y_col].min(), data[y_col].max()\n",
        "\n",
        "# Create grid resolution\n",
        "x_res = int((x_max - x_min) / pixel_size) + 1\n",
        "y_res = int((y_max - y_min) / pixel_size) + 1\n",
        "\n",
        "for band in bands.keys():\n",
        "    # Initialize an empty array for the raster (NaNs for no data)\n",
        "    raster_data = np.full((y_res, x_res), np.nan)\n",
        "\n",
        "    # Map DataFrame coordinates to the grid\n",
        "    for index, row in data.iterrows():\n",
        "        # Use round() and clip to avoid out-of-bounds errors\n",
        "        col = np.clip(round((row[x_col] - x_min) / pixel_size), 0, x_res - 1)\n",
        "        row_ = np.clip(round((y_max - row[y_col]) / pixel_size), 0, y_res - 1)  # Y-axis is inverted in rasters\n",
        "\n",
        "        # Set the value in the raster data (e.g., p-value for slope)\n",
        "        raster_data[row_, col] = row[band]\n",
        "\n",
        "    # Define transformation (mapping pixel coordinates to geographic coordinates)\n",
        "    transform = from_origin(x_min, y_max, pixel_size, pixel_size)\n",
        "\n",
        "    with rasterio.open(\n",
        "        f'gdrive/MyDrive/output/R_Deg_Rasters/{bands[band]}_raster.tif', 'w',\n",
        "        driver='GTiff',\n",
        "        height=raster_data.shape[0],\n",
        "        width=raster_data.shape[1],\n",
        "        count=1,\n",
        "        dtype=raster_data.dtype,\n",
        "        crs='EPSG:4326',\n",
        "        transform=transform\n",
        "    ) as dst:\n",
        "        dst.write(raster_data, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtptUSvX5GN8",
        "outputId": "a70d9ab8-dbf3-4c0c-b448-8b0491704eed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}